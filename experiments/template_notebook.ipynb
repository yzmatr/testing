{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7f4ff23",
   "metadata": {},
   "source": [
    "# Experiment & Config Setup\n",
    "\n",
    "Before starting any experiment, you should define the `EXPERIMENT_NAME` (ideally, matching the name of the notebook) and the baseline configuration for all the classes that will be used across the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bd6ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "#-------------------------------------------------------------------------------\n",
    "# REQUIRED PACKAGES\n",
    "#-------------------------------------------------------------------------------\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from databricks.sdk.runtime import *\n",
    "notebook_path =  '/Workspace/' + os.path.dirname(dbutils.notebook.entry_point.getDbutils().notebook().getContext().notebookPath().get())\n",
    "os.chdir(notebook_path)\n",
    "os.chdir('..')\n",
    "sys.path.append(\"../..\")\n",
    "from mlops.utils.environment_setup import start_experiment\n",
    "\n",
    "#-------------------------------------------------------------------------------\n",
    "# CONFIGURABLE OPTIONS\n",
    "#-------------------------------------------------------------------------------\n",
    "EXPERIMENT_NAME = \"birdnet-average-3s-chunk-embeddings\"     # Experiment name (should match notebook name)\n",
    "CURRENT_USER=\"saleem.ameen@matrgroup.com\"                   # Author email address on databricks             \n",
    "\n",
    "#-------------------------------------------------------------------------------\n",
    "# SYSTEM SETUP FOR EXPERIMENT\n",
    "#-------------------------------------------------------------------------------\n",
    "IS_DATABRICKS = \"DATABRICKS_RUNTIME_VERSION\" in os.environ\n",
    "ROOT_DIR = Path(os.getcwd()).parent\n",
    "sys.path.insert(0, str(ROOT_DIR))\n",
    "experiment = start_experiment(\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    root_dir=ROOT_DIR, \n",
    "    is_databricks=IS_DATABRICKS, \n",
    "    current_user=CURRENT_USER\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc79668",
   "metadata": {},
   "source": [
    "# Run Setup\n",
    "\n",
    "In the following section you can run a version of this experiment by defining a run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775aed42",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# START MLFLOW RUN\n",
    "################################################################################\n",
    "# This an be a new run (run_id = None) or an existing run that you want to\n",
    "# reload, by specifying the run_id\n",
    "################################################################################\n",
    "from utils.environment_setup import start_mlflow_run\n",
    "from utils.pipeline import generate_pipeline_config, instantiate_pipeline\n",
    "\n",
    "run_name, run_id = start_mlflow_run(run_id=\"de0d86ce189d41548fe5b679ed33d63e\")\n",
    "config = generate_pipeline_config(experiment, run_id, force_save=True)\n",
    "pipeline = instantiate_pipeline(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33216c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# LOAD CLEAN DATA\n",
    "################################################################################\n",
    "# The anchoring function determines how you select the class_label_single\n",
    "# from a list of species in multi-species settings. Below we use the\n",
    "# most-frequent-target strategy, which means that if there are multiple species\n",
    "# the single class label will be the species that is most frequently represented\n",
    "# among the list of class labels.\n",
    "################################################################################\n",
    "\n",
    "from feature_engineering.registry_anchoring_strategies import ANCHORING_STRATEGY_REGISTRY\n",
    "\n",
    "# Load the cleaned data and their classes\n",
    "df_data, class_labels_to_species_mapping = pipeline.data_selector.load_data(\n",
    "    label_anchor_fn=ANCHORING_STRATEGY_REGISTRY[\"most-frequent-target\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e710cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# MODELLING\n",
    "################################################################################\n",
    "# The following code snippet demonstrates how to produce a reproducible ML\n",
    "# model training pipeline. The process involves:\n",
    "# 1. Selecting the subset of data to use for modelling based on a strategy\n",
    "# 2. Downloading & Preprocessing the selected subset to create a feature df\n",
    "# 3. Training the model according to the initial experiment setup\n",
    "################################################################################\n",
    "from mlops.training.tf_model_registry import MODEL_REGISTRY\n",
    "\n",
    "# Step 1: Sample the modelling data using the data_sampler\n",
    "df_modelling = pipeline.data_sampler.sample_modelling_dataset(\n",
    "    df_data=df_data,\n",
    "    modelling_strategy=config.modelling_data_strategy,\n",
    ")\n",
    "\n",
    "# df_modelling = df_modelling.head(100) -- test purspose\n",
    "\n",
    "# Step 2: Download the data and return the updated dataframe (in case of missing files)\n",
    "df_modelling = pipeline.data_downloader.download_files(df_modelling)\n",
    "\n",
    "# Step 3: Create embeddings for the data using the data_preprocessor\n",
    "df_modelling_features = pipeline.data_preprocessor.run(df_modelling)\n",
    "\n",
    "# Step 4: Train the model\n",
    "model = pipeline.model_trainer.train(df_modelling_features, model_fn=MODEL_REGISTRY['birdnet_mlp_multiclass'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da63b958",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# EVALUATION: TEST DATA\n",
    "################################################################################\n",
    "# The following code snippet demonstrates how to do an evaluation of a model\n",
    "# 1. Select a sample you are interested in using the data_sampler\n",
    "# 2. Downloading & Preprocessing the selected subset to create a feature df\n",
    "# 3. Evaluating the model by pointing to the correct run_id\n",
    "################################################################################\n",
    "\n",
    "# Sample the data you are interested in\n",
    "df_sample = pipeline.data_sampler.sample_test_data(run_id=run_id, df=df_data)\n",
    "\n",
    "# Download any files required to evaluate this sample\n",
    "df_sample = pipeline.data_downloader.download_files(df_sample)\n",
    "\n",
    "# Create embeddings for the data using this sample\n",
    "df_sample_features = pipeline.data_preprocessor.run(df_sample)\n",
    "\n",
    "# Evaluate the results for the model stored inside the given run_id\n",
    "y_true, y_true_binarized, y_pred, y_probs, macro_results, per_species_results = pipeline.model_evaluator.evaluate(\n",
    "    run_id=run_id,\n",
    "    df_features=df_sample_features,\n",
    "    class_label_to_species_mapping=class_labels_to_species_mapping,\n",
    "    dir_name_to_store_results=\"single-species-max-1000\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ee2f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# EVALUATION: HOLDOUT DATA\n",
    "################################################################################\n",
    "# The following code snippet demonstrates how to do an evaluation of a model\n",
    "# 1. Select a sample you are interested in using the data_sampler\n",
    "# 2. Downloading & Preprocessing the selected subset to create a feature df\n",
    "# 3. Evaluating the model by pointing to the correct run_id\n",
    "################################################################################\n",
    "from feature_engineering.registry_filtering_strategies import FILTERING_STRATEGY_REGISTRY\n",
    "\n",
    "# Sample the data you are interested in\n",
    "df_sample = pipeline.data_sampler.sample_hold_out_data(\n",
    "    run_id=run_id,\n",
    "    df_cleaned=df_data,\n",
    "    filtering_strategy_fn=FILTERING_STRATEGY_REGISTRY['single-species-only'],\n",
    "    max_samples_per_class=100,\n",
    ")\n",
    "\n",
    "# Download any files required to evaluate this sample\n",
    "df_sample = pipeline.data_downloader.download_files(df_sample)\n",
    "\n",
    "# Create embeddings for the data using this sample\n",
    "df_sample_features = pipeline.data_preprocessor.run(df_sample)\n",
    "\n",
    "# Evaluate the results for the model stored inside the given run_id\n",
    "y_true, y_true_binarized, y_pred, y_probs, macro_results, per_species_results = pipeline.model_evaluator.evaluate(\n",
    "    run_id=run_id,\n",
    "    df_features=df_sample_features,\n",
    "    class_label_to_species_mapping=class_labels_to_species_mapping,\n",
    "    dir_name_to_store_results=\"holdout-data-max-100\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a45aec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# HELPFUL UTILITIES\n",
    "################################################################################\n",
    "# This section describes how you might choose to use some helpful utilities\n",
    "################################################################################\n",
    "from utils.cache_utils import clear_cache\n",
    "from dataclasses import replace\n",
    "\n",
    "# You can clear local directories by specifying what ids you want to keep\n",
    "deleted_files_list = clear_cache(\n",
    "    directory=experiment[\"audio_files_path\"],\n",
    "    keep_ids=[],\n",
    "    keep_extensions={\"wav\"}\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
