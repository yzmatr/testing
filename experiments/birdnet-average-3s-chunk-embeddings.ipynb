{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1a259914-ee30-4e9b-a812-e393adb11ced",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Experiment & Config Setup\n",
    "\n",
    "Before starting any experiment, you should define the `EXPERIMENT_NAME` (ideally, matching the name of the notebook) and the baseline configuration for all the classes that will be used across the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44f358a5-6515-4297-9c1b-17eb9b4656a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "#-------------------------------------------------------------------------------\n",
    "# REQUIRED PACKAGES\n",
    "#-------------------------------------------------------------------------------\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "#-------------------------------------------------------------------------------\n",
    "# CONFIGURABLE OPTIONS\n",
    "#-------------------------------------------------------------------------------\n",
    "EXPERIMENT_NAME = \"birdnet-ave-3s-chunk-embeddings\"     # Experiment name (should match notebook name)\n",
    "SCHEMA = \"frogid_ml\"\n",
    "MODEL_NAME = \"birdnet-ave-3s-chunk-embeddings\"\n",
    "CURRENT_USER=\"yulin.zhou@matrgroup.com\"                   # Author email address on databricks             \n",
    "\n",
    "#-------------------------------------------------------------------------------\n",
    "# SYSTEM SETUP FOR EXPERIMENT\n",
    "#-------------------------------------------------------------------------------\n",
    "IS_DATABRICKS = \"DATABRICKS_RUNTIME_VERSION\" in os.environ\n",
    "ROOT_DIR = Path(os.getcwd()).parent\n",
    "sys.path.insert(0, str(ROOT_DIR))\n",
    "from mlops.utils.environment_setup import start_experiment\n",
    "experiment = start_experiment(\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    root_dir=ROOT_DIR, \n",
    "    is_databricks=IS_DATABRICKS, \n",
    "    current_user=CURRENT_USER\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a9fdd30-de45-4479-8b86-fcc2c9bc97af",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ROOT_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8e943c88-fde3-49eb-9baa-6bf3b564d5c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Run Setup\n",
    "\n",
    "In the following section you can run a version of this experiment by defining a run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "871cddf7-7f20-4bf1-83e3-49f2af5343c9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# START MLFLOW RUN\n",
    "################################################################################\n",
    "# This an be a new run (run_id = None) or an existing run that you want to\n",
    "# reload, by specifying the run_id\n",
    "################################################################################\n",
    "from mlops.utils.environment_setup import start_mlflow_run\n",
    "from mlops.utils.pipeline import generate_pipeline_config, instantiate_pipeline\n",
    "\n",
    "run_name, run_id = start_mlflow_run(run_id = None)\n",
    "config = generate_pipeline_config(\n",
    "    experiment, \n",
    "    run_id, \n",
    "    force_save=True,\n",
    "    overrides={\n",
    "        'mlflow_config.log_model_wrapper': True\n",
    "    }\n",
    ")\n",
    "pipeline = instantiate_pipeline(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63acd6fa-2609-4969-96fb-bc62e7bb56fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# LOAD CLEAN DATA\n",
    "################################################################################\n",
    "# The anchoring function determines how you select the class_label_single\n",
    "# from a list of species in multi-species settings. Below we use the\n",
    "# most-frequent-target strategy, which means that if there are multiple species\n",
    "# the single class label will be the species that is most frequently represented\n",
    "# among the list of class labels.\n",
    "################################################################################\n",
    "\n",
    "from mlops.feature_engineering.registry_anchoring_strategies import ANCHORING_STRATEGY_REGISTRY\n",
    "\n",
    "# Load the cleaned data and their classes\n",
    "df_data, class_labels_to_species_mapping = pipeline.data_selector.load_data(\n",
    "    label_anchor_fn=ANCHORING_STRATEGY_REGISTRY[\"most-frequent-target\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "00dc9692-50b1-4f1e-95d9-c3d51f9028ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# MODELLING\n",
    "################################################################################\n",
    "# The following code snippet demonstrates how to produce a reproducible ML\n",
    "# model training pipeline. The process involves:\n",
    "# 1. Selecting the subset of data to use for modelling based on a strategy\n",
    "# 2. Downloading & Preprocessing the selected subset to create a feature df\n",
    "# 3. Training the model according to the initial experiment setup\n",
    "################################################################################\n",
    "from mlops.training.tf_model_registry import MODEL_REGISTRY\n",
    "\n",
    "# Step 1: Sample the modelling data using the data_sampler\n",
    "df_modelling = pipeline.data_sampler.sample_modelling_dataset(\n",
    "    df_data=df_data,\n",
    "    modelling_strategy=config.modelling_data_strategy,\n",
    ")\n",
    "\n",
    "df_modelling = df_modelling.head(1000)\n",
    "\n",
    "# Step 2: Download the data and return the updated dataframe (in case of missing files)\n",
    "df_modelling = pipeline.data_downloader.download_files(df_modelling)\n",
    "\n",
    "# Step 3: Create embeddings for the data using the data_preprocessor\n",
    "df_modelling_features = pipeline.data_preprocessor.run(df_modelling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "74697daa-4193-4f5d-845d-a46ec9ec23bf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Step 4: Train the model\n",
    "model = pipeline.model_trainer.train(df_modelling_features, model_fn=MODEL_REGISTRY['birdnet_mlp_multiclass'], name = f\"{SCHEMA}.{MODEL_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b504ce9a-2938-4b14-90c1-56683244cd5f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# EVALUATION: TEST DATA\n",
    "################################################################################\n",
    "# The following code snippet demonstrates how to do an evaluation of a model\n",
    "# 1. Select a sample you are interested in using the data_sampler\n",
    "# 2. Downloading & Preprocessing the selected subset to create a feature df\n",
    "# 3. Evaluating the model by pointing to the correct run_id\n",
    "################################################################################\n",
    "\n",
    "# Sample the data you are interested in\n",
    "df_sample = pipeline.data_sampler.sample_test_data(run_id=run_id, df=df_data)\n",
    "\n",
    "# Download any files required to evaluate this sample\n",
    "df_sample = pipeline.data_downloader.download_files(df_sample)\n",
    "\n",
    "# Create embeddings for the data using this sample\n",
    "df_sample_features = pipeline.data_preprocessor.run(df_sample)\n",
    "\n",
    "# Evaluate the results for the model stored inside the given run_id\n",
    "y_true, y_true_binarized, y_pred, y_probs, macro_results, per_species_results = pipeline.model_evaluator.evaluate(\n",
    "    run_id=run_id,\n",
    "    df_features=df_sample_features,\n",
    "    class_label_to_species_mapping=class_labels_to_species_mapping,\n",
    "    dir_name_to_store_results=\"single-species-max-1000\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1b2b4de9-a917-4a15-82cc-df2420cb77d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# EVALUATION: HOLDOUT DATA\n",
    "################################################################################\n",
    "# The following code snippet demonstrates how to do an evaluation of a model\n",
    "# 1. Select a sample you are interested in using the data_sampler\n",
    "# 2. Downloading & Preprocessing the selected subset to create a feature df\n",
    "# 3. Evaluating the model by pointing to the correct run_id\n",
    "################################################################################\n",
    "from mlops.feature_engineering.registry_filtering_strategies import FILTERING_STRATEGY_REGISTRY\n",
    "\n",
    "# Sample the data you are interested in\n",
    "df_sample = pipeline.data_sampler.sample_hold_out_data(\n",
    "    run_id=run_id,\n",
    "    df_cleaned=df_data,\n",
    "    filtering_strategy_fn=FILTERING_STRATEGY_REGISTRY['single-species-only'],\n",
    "    max_samples_per_class=100,\n",
    ")\n",
    "\n",
    "# Download any files required to evaluate this sample\n",
    "df_sample = pipeline.data_downloader.download_files(df_sample)\n",
    "\n",
    "# Create embeddings for the data using this sample\n",
    "df_sample_features = pipeline.data_preprocessor.run(df_sample)\n",
    "\n",
    "# Evaluate the results for the model stored inside the given run_id\n",
    "y_true, y_true_binarized, y_pred, y_probs, macro_results, per_species_results = pipeline.model_evaluator.evaluate(\n",
    "    run_id=run_id,\n",
    "    df_features=df_sample_features,\n",
    "    class_label_to_species_mapping=class_labels_to_species_mapping,\n",
    "    dir_name_to_store_results=\"holdout-data-max-100\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1f5e2c3d-44dc-4fdf-9e19-4dc3bdedac22",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "def get_latest_model_version(model_name):\n",
    "    latest_version = 1\n",
    "    mlflow_client = MlflowClient()\n",
    "    for mv in mlflow_client.search_model_versions(f\"name='{model_name}'\"):\n",
    "        version_int = int(mv.version)\n",
    "        if version_int > latest_version:\n",
    "            latest_version = version_int\n",
    "    return latest_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "332773dd-0f2c-490a-bf68-d5ecfa80a168",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "catalog = \"Aus_Museum_DBX_Prod\" if \"prod\" in str(ROOT_DIR) else \"Aus_Museum_DBX_Dev\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3ba402f2-b7ff-428e-b177-8520abaa961e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# The returned model URI is needed by the model deployment notebook.\n",
    "model_name =  f\"{catalog}.{SCHEMA}.{MODEL_NAME}\"\n",
    "model_version = get_latest_model_version(model_name)\n",
    "model_uri = f\"models:/{model_name}/{model_version}\"\n",
    "dbutils.jobs.taskValues.set(\"model_uri\", model_uri)\n",
    "dbutils.jobs.taskValues.set(\"model_name\", model_name)\n",
    "dbutils.jobs.taskValues.set(\"model_version\", model_version)\n",
    "dbutils.notebook.exit(model_uri)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "birdnet-average-3s-chunk-embeddings",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
