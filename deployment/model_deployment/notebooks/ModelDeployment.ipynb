{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cd60c6fa-583d-401d-8caa-50c776770e17",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "# Helper notebook to transition the model stage. This notebook is run\n",
    "# after the Train.py notebook as part of a multi-task job, in order to transition model\n",
    "# to target stage after training completes.\n",
    "#\n",
    "# Note that we deploy the model to the stage in MLflow Model Registry equivalent to the\n",
    "# environment in which the multi-task job is executed (e.g deploy the trained model to\n",
    "# stage=Production if triggered in the prod environment). In a practical setting, we would\n",
    "# recommend enabling the model validation step between  model training and automatically\n",
    "# registering the model to the Production stage in prod.\n",
    "#\n",
    "# This notebook has the following parameters:\n",
    "#\n",
    "#  * env (required)  - String name of the current environment for model deployment, which decides the target stage.\n",
    "#  * model_uri (required)  - URI of the model to deploy. Must be in the format \"models:/<name>/<version-id>\", as described in\n",
    "#                            https://www.mlflow.org/docs/latest/model-registry.html#fetching-an-mlflow-model-from-the-model-registry\n",
    "#                            This parameter is read as a task value\n",
    "#                            (https://docs.databricks.com/dev-tools/databricks-utils.html),\n",
    "#                            rather than as a notebook widget. That is, we assume a preceding task (the Train.py\n",
    "#                            notebook) has set a task value with key \"model_uri\".\n",
    "##################################################################################\n",
    "\n",
    "# List of input args needed to run the notebook as a job.\n",
    "# Provide them via DB widgets or notebook arguments.\n",
    "#\n",
    "from databricks.sdk.runtime import *\n",
    "# Name of the current environment\n",
    "dbutils.widgets.dropdown(\"env\", \"None\", [\"None\", \"staging\", \"prod\"], \"Environment Name\")\n",
    "\n",
    "import os\n",
    "import sys\n",
    "notebook_path =  '/Workspace/' + os.path.dirname(dbutils.notebook.entry_point.getDbutils().notebook().getContext().notebookPath().get())\n",
    "os.chdir(notebook_path)\n",
    "os.chdir('..')\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "from deploy import deploy\n",
    "\n",
    "model_uri = dbutils.jobs.taskValues.get(\"Train\", \"model_uri\", debugValue=\"\")\n",
    "env = dbutils.widgets.get(\"env\")\n",
    "assert env != \"None\", \"env notebook parameter must be specified\"\n",
    "assert model_uri != \"\", \"model_uri notebook parameter must be specified\"\n",
    "deploy(model_uri, env)\n",
    "\n",
    "print(\n",
    "    f\"Successfully completed model deployment for {model_uri}\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "ModelDeployment",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}